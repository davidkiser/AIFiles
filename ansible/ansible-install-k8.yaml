---
- name: Setup Ubuntu 24.04 for AI workloads with MicroK8s
  hosts: all
  become: true
  vars:
    static_ip: "192.168.1.240"
    gateway: "192.168.1.1"
    dns_servers: ["1.1.1.1", "8.8.8.8"]
    interface_name: "wlxb0594700cb17"
    local_user: "david"
    longhorn_namespace: longhorn
    longhorn_release_name: longhorn
    longhorn_helm_repo: longhorn/longhorn
    longhorn_values_file: /home/david/Code/AIFiles/helm/longhorn-values.yaml
    ansible_python_interpreter: /home/{{ local_user }}/ai-venv/bin/python
    K8S_AUTH_KUBECONFIG: /home/{{ local_user }}/.kube/config
    ai_namespace: "ai"
  vars_files:
    - ansible-vars.yaml

  tasks:

    - name: Install Docker prerequisites
      apt:
        name:
          - apt-transport-https
          - ca-certificates
          - curl
          - gnupg
          - lsb-release
        state: present
        update_cache: true

    - name: Add Docker GPG key
      apt_key:
        url: https://download.docker.com/linux/ubuntu/gpg
        state: present

    - name: Add Docker apt repository
      apt_repository:
        repo: "deb [arch=amd64] https://download.docker.com/linux/ubuntu {{ ansible_distribution_release }} stable"
        state: present
        filename: docker

    - name: Install Docker Engine
      apt:
        name:
          - docker-ce
          - docker-ce-cli
          - containerd.io
        state: present
        update_cache: true

    - name: Install MicroK8s
      snap:
        name: microk8s
        classic: true

    - name: Add '{{ local_user }}' to sudo and docker groups
      user:
        name: "{{ local_user }}"
        groups: sudo,docker,microk8s
        append: yes

    - name: Install required base packages
      apt:
        name:
          - python3-pip
          - curl
          - gnupg
          - ca-certificates
          - git
        state: present
        update_cache: true

    - name: Wait for MicroK8s to be ready
      shell: microk8s status --wait-ready
      register: mk8s_status
      retries: 5
      delay: 10
      until: mk8s_status.rc == 0

    - name: Enable useful MicroK8s add-ons
      shell: |
        microk8s enable dns storage ingress dashboard
        microk8s enable gpu || true  # Will succeed only if supported
      args:
        executable: /bin/bash

    - name: Create .kube directory for user
      file:
        path: /home/{{ local_user }}/.kube
        state: directory
        owner: "{{ local_user }}"
        group: "{{ local_user }}"
        mode: '0755'

    - name: Retrieve MicroK8s kubeconfig
      command: microk8s config
      register: kubeconfig

    - name: Write kubeconfig to user's .kube/config
      copy:
        content: "{{ kubeconfig.stdout }}"
        dest: "/home/{{ local_user }}/.kube/config"
        owner: "{{ local_user }}"
        group: "{{ local_user }}"
        mode: '0600'

    - name: Add NVIDIA libnvidia-container GPG key
      shell: |
        curl -fsSL https://nvidia.github.io/libnvidia-container/gpgkey | gpg --dearmor -o /usr/share/keyrings/nvidia-container-toolkit-keyring.gpg
      args:
        creates: /usr/share/keyrings/nvidia-container-toolkit-keyring.gpg

    - name: Add NVIDIA libnvidia-container stable repository
      shell: |
        curl -s -L https://nvidia.github.io/libnvidia-container/stable/deb/nvidia-container-toolkit.list | \
        sed 's#deb https://#deb [signed-by=/usr/share/keyrings/nvidia-container-toolkit-keyring.gpg] https://#g' | \
        tee /etc/apt/sources.list.d/nvidia-container-toolkit.list
      args:
        executable: /bin/bash

    - name: Update apt after adding NVIDIA repo
      apt:
        update_cache: true

    - name: Set NVIDIA Container Toolkit version as a fact
      set_fact:
        nvidia_toolkit_version: "1.17.8-1"

    - name: Install NVIDIA Container Toolkit and dependencies
      apt:
        name:
          - "nvidia-container-toolkit={{ nvidia_toolkit_version }}"
          - "nvidia-container-toolkit-base={{ nvidia_toolkit_version }}"
          - "libnvidia-container-tools={{ nvidia_toolkit_version }}"
          - "libnvidia-container1={{ nvidia_toolkit_version }}"
        state: present

    - name: Install NVIDIA GPU driver (if applicable)
      shell: |
        ubuntu-drivers devices | grep recommended | awk '{print $3}' | xargs -I{} apt install -y {}
      register: driver_install
      changed_when: "'installed' in driver_install.stdout"

    - name: Restart containerd
      service:
        name: containerd
        state: restarted
        enabled: true

    - name: Ensure venv module is installed
      apt:
        name: python3-venv
        state: present

    - name: Create a Python virtual environment
      command: python3 -m venv /home/{{ local_user }}/ai-venv
      args:
        creates: /home/{{ local_user }}/ai-venv

    - name: Install AI libraries into the virtual environment
      pip:
        name:
          - torch
          - torchvision
          - transformers
          - jupyterlab
          - kubernetes
          - openshift
        virtualenv: /home/{{ local_user }}/ai-venv
        virtualenv_command: python3 -m venv
        virtualenv_python: python3
        state: present

    - name: Ensure user owns virtualenv
      file:
        path: /home/{{ local_user }}/ai-venv
        state: directory
        recurse: yes
        owner: "{{ local_user }}"
        group: "{{ local_user }}"

    - name: Download Helm install script
      get_url:
        url: https://raw.githubusercontent.com/helm/helm/main/scripts/get-helm-3
        dest: /tmp/get_helm.sh
        mode: '0755'

    - name: Run Helm install script
      command: /tmp/get_helm.sh
      args:
        creates: /usr/local/bin/helm

    - name: Verify Helm installation
      command: helm version
      register: helm_version
      changed_when: false

    - name: Ensure snapd is installed
      apt:
        name: snapd
        state: present
        update_cache: yes

    - name: Ensure core snap is installed
      snap:
        name: core
        state: present

    - name: Install kubectl via snap with classic confinement
      shell: snap install kubectl --classic
      args:
        creates: /snap/bin/kubectl

    - name: Ensure Helm is installed
      command: helm version
      register: helm_check
      failed_when: helm_check.rc != 0
      ignore_errors: false

    - name: Install required packages for Longhorn
      apt:
        name:
          - open-iscsi
          - nfs-common
        state: present
        update_cache: true

    - name: Ensure iSCSI daemon is enabled and running
      systemd:
        name: iscsid
        enabled: true
        state: started

    - name: Add Longhorn Helm repository
      shell: |
        helm repo add longhorn https://charts.longhorn.io
        helm repo update
      environment:
        KUBECONFIG: "{{ lookup('env', 'KUBECONFIG') | default('/home/david/.kube/config', true) }}"

    - name: Ensure Longhorn namespace exists
      kubernetes.core.k8s:
        api_version: v1
        kind: Namespace
        name: "{{ longhorn_namespace }}"
        state: present
      environment:
        K8S_AUTH_KUBECONFIG: "{{ K8S_AUTH_KUBECONFIG }}"

    - name: Deploy Longhorn via Helm
      shell: |
        helm upgrade --install {{ longhorn_release_name }} {{ longhorn_helm_repo }} \
          --namespace {{ longhorn_namespace }} \
          -f {{ longhorn_values_file }}
      environment:
        KUBECONFIG: "{{ lookup('env', 'KUBECONFIG') | default('/home/david/.kube/config', true) }}"

    - name: Display Longhorn dashboard access instructions
      debug:
        msg: |
          Longhorn is installed.
          To access the dashboard:
            kubectl port-forward -n {{ longhorn_namespace }} svc/longhorn-frontend 8081:80
            Visit: http://localhost:8081

    - name: Ensure AI namespace exists
      kubernetes.core.k8s:
        api_version: v1
        kind: Namespace
        name: "{{ ai_namespace }}"
        state: present
      environment:
        K8S_AUTH_KUBECONFIG: "{{ K8S_AUTH_KUBECONFIG }}"

    # --- Open WebUI: repo + install (NodePort) ---
    - name: Add/ensure Open WebUI Helm repo
      ansible.builtin.command: >
        helm repo add open-webui https://helm.openwebui.com
      register: ow_repo_add
      changed_when: >
        ('has been added' in (ow_repo_add.stdout + ow_repo_add.stderr))
        or ('already exists' not in (ow_repo_add.stdout + ow_repo_add.stderr))
      failed_when: ow_repo_add.rc != 0 and
                   ('already exists' not in (ow_repo_add.stdout + ow_repo_add.stderr))

    - name: Helm repo update
      ansible.builtin.command: helm repo update

    - name: Install/upgrade Open WebUI with NodePort
      ansible.builtin.command: >
        helm upgrade --install open-webui open-webui/open-webui
        -n ai --create-namespace
        -f /home/david/Code/AIFiles/helm/openwebui-values.yaml
        --set service.type=NodePort
        --set service.nodePort=30080
        --wait
      register: ow_install
      environment:
        KUBECONFIG: "{{ lookup('env', 'KUBECONFIG') | default('/home/david/.kube/config', true) }}"

    - name: Show Open WebUI service
      ansible.builtin.command: kubectl -n ai get svc open-webui -o wide
      changed_when: false
      environment:
        KUBECONFIG: "{{ lookup('env', 'KUBECONFIG') | default('/home/david/.kube/config', true) }}"

    - name: Wait for Open WebUI StatefulSet to be ready
      ansible.builtin.command: >
        kubectl -n ai rollout status statefulset/open-webui --timeout=5m
      environment:
        KUBECONFIG: "{{ lookup('env', 'KUBECONFIG') | default('/home/david/.kube/config', true) }}"

# ========================= UNINSTALL / CLEANUP =========================
- name: Uninstall/cleanup MicroK8s and k8s add-ons
  hosts: all
  become: true
  gather_facts: false
  vars:
    local_user: "david"
    kubeconfig_path: "/home/{{ local_user }}/.kube/config"
  tasks:
    - name: Try to uninstall Helm releases (best-effort)
      ansible.builtin.shell: |
        set -euo pipefail
        export KUBECONFIG="{{ kubeconfig_path }}"
        for pair in "ai open-webui" "longhorn longhorn"; do
          set -- $pair
          ns="$1"; rel="$2"
          if helm status "$rel" -n "$ns" >/dev/null 2>&1; then
            helm uninstall "$rel" -n "$ns" || true
          fi
        done
      args:
        executable: /bin/bash
      changed_when: false
      failed_when: false
      tags: [uninstall]

    - name: Delete namespaces (best-effort)
      ansible.builtin.shell: |
        set -euo pipefail
        export KUBECONFIG="{{ kubeconfig_path }}"
        for ns in ai longhorn; do
          kubectl delete ns "$ns" --ignore-not-found --wait=false || true
        done
      args: { executable: /bin/bash }
      changed_when: false
      tags: [uninstall]

    - name: Stop MicroK8s (ignore if absent)
      ansible.builtin.command: microk8s stop
      register: stop_out
      failed_when: false
      changed_when: "'stopped' in (stop_out.stdout | default('')) or stop_out.rc == 0"
      tags: [uninstall]

    - name: Reset MicroK8s and destroy storage (DANGEROUS)
      ansible.builtin.command: microk8s reset --destroy-storage
      register: reset_out
      failed_when: false
      changed_when: reset_out.rc == 0
      tags: [uninstall]

    - name: Remove MicroK8s snap (purge)
      ansible.builtin.snap:
        name: microk8s
        state: absent
      tags: [uninstall]

    - name: Clean leftover MicroK8s & CNI directories
      ansible.builtin.file:
        path: "{{ item }}"
        state: absent
      loop:
        - /var/snap/microk8s
        - /var/lib/cni
        - /etc/cni/net.d
        - /opt/cni/bin
      tags: [uninstall]

    - name: Remove stray CNI bridges (ignore errors)
      ansible.builtin.shell: |
        ip link delete cni0 2>/dev/null || true
        ip link delete flannel.1 2>/dev/null || true
      args: { executable: /bin/bash }
      changed_when: false
      tags: [uninstall]
# ======================= END UNINSTALL / CLEANUP =======================

